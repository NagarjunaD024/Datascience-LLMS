{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzPbD64l+Xy1IpXHduG7Yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NagarjunaD024/Datascience-LLMS/blob/main/src/GPT_Alternatives/cohere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRuYsiCRGuSC",
        "outputId": "7d54b9b3-b5fe-4acb-dc8d-c962bd8d918e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.11.7)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.2)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.14.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.5)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.15.0 fastavro-1.11.1 httpx-sse-0.4.0 types-requests-2.32.4.20250611\n"
          ]
        }
      ],
      "source": [
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import cohere"
      ],
      "metadata": {
        "id": "oruV6UuZHCM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " client = cohere.Client(\"your_api_key\")\n",
        "\n",
        "prompt = f'Answer this question: {\"What are webconnectors in context of Large Language models?.\"}'\n",
        "result = client.chat(message= prompt, connectors=[{'id': 'web-search'}])\n",
        "\n",
        "print(f'Answer: {result.text}')\n",
        "print(f'Web searches: {result.search_results}')\n",
        "print(f'Web results: {result.documents}')"
      ],
      "metadata": {
        "id": "0Tg36SmWH8lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a845dd5-c692-4c77-aeea-f766c8a749d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Webconnectors, or connectors, in the context of Large Language Models (LLMs), are components that bridge diverse modalities and enhance model performance. They play a crucial role in aligning multi-modal inputs into a consistent form and space, and translate modality features into tokens that the language model can understand.\n",
            "\n",
            "The design and evolution of connectors have not been comprehensively analyzed, which has created gaps in understanding how these components function and hindered the development of more powerful connectors. However, researchers have been working on providing valuable insights into the design and optimization of next-generation connectors to enhance the performance and adaptability of multi-modal large language models (MLLMs).\n",
            "\n",
            "In a unified multi-task learning framework, task-specific information provides critical context for the connector to classify tokens and determine the most suitable experts. This has led to the development of models like Uni-Med, which employs a well-designed router to calculate routing weights and activate different experts for each task.\n",
            "\n",
            "Overall, webconnectors are an essential component in the development of MLLMs, and ongoing research aims to provide a comprehensive understanding of their design and functionality.\n",
            "Web searches: [ChatSearchResult(search_query=ChatSearchQuery(text='{\"tool_name\":\"internet_search\",\"parameters\":{\"query\":\"webconnectors in context of Large Language models\"}}', generation_id=None), connector=ChatSearchResultConnector(id='internet_search'), document_ids=['internet_search_0_1_0', 'internet_search_1_1_0', 'internet_search_2_1_0', 'internet_search_3_1_0', 'internet_search_4_1_0'], error_message=None, continue_on_failure=None)]\n",
            "Web results: [{'id': 'internet_search_2_1_0', 'snippet': 'In the above paradigm, the connector plays a crucial role in aligning the multi-modal inputs into a consistent form and space (Cha et al., 2024): On the one hand, the connector bridges modalities and the language model by translating modality features into tokens that the language model can understand.', 'timestamp': '', 'title': 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models', 'url': 'https://arxiv.org/html/2502.11453'}, {'id': 'internet_search_4_1_0', 'snippet': 'With the rapid advancements in multi-modal large language models (MLLMs), connectors play a pivotal role in bridging diverse modalities and enhancing model performance. However, the design and evolution of connectors have not been comprehensively analyzed, leaving gaps in understanding how these components function and hindering the development of more powerful connectors.', 'timestamp': '', 'title': '[2502.11453] Connector-S: A Survey of Connectors in Multi-modal Large Language Models', 'url': 'https://arxiv.org/abs/2502.11453'}, {'id': 'internet_search_1_1_0', 'snippet': 'This survey is intended to serve as a foundational reference and a clear roadmap for researchers, providing valuable insights into the design and optimization of next-generation connectors to enhance the performance and adaptability of MLLMs. With the remarkable advancements in large language models (LLMs) propelling progress towards general-purpose AI, there has been a significant growing focus on extending these models to multi-modal domains, leading to the development of multi-model large language models (MLLMs).', 'timestamp': '', 'title': 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models', 'url': 'https://arxiv.org/html/2502.11453'}, {'id': 'internet_search_3_1_0', 'snippet': 'The development of connectors in multi-modal large language models has become a critical area of research as the field progresses towards general AI. In this survey, we aim to provide an in-depth overview of the connector in existing MLLMs. Firstly, we introduce a new taxonomy that categorizes connectors into atomic operations and holistic designs.', 'timestamp': '', 'title': 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models', 'url': 'https://arxiv.org/html/2502.11453'}, {'id': 'internet_search_0_1_0', 'snippet': 'In a unified multi-task learning framework, task-specific information provides critical context for the connector to classify tokens and determine the most suitable experts. Uni-Med (Zhu et al., 2024a) introduces a unified medical foundation model that employs C-MoE, a well-designed router which calculates routing weights based on concatenated visual and task-specific tokens and activates different experts for each task, efficiently addressing the multi-task interference problem in MLLMs.', 'timestamp': '', 'title': 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models', 'url': 'https://arxiv.org/html/2502.11453'}]\n"
          ]
        }
      ]
    }
  ]
}